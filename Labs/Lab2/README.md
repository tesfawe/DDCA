# Data Warehousing and Data Lakes with Spark + Hive

## Introduction
This project explores two fundamental data engineering paradigms:  

1. **Data Warehouse (Schema-on-Write)**
   - Data is cleansed, transformed, and loaded into structured tables before analysis.  
   - Ensures data consistency and optimized querying.  

2. **Data Lake (Schema-on-Read)**
   - Stores raw data without predefined structure.  
   - The schema is applied dynamically at query time for flexibility.  

## Objective
This exercise demonstrates both **ETL (Extract, Transform, Load)** and **ELT (Extract, Load, Transform)** approaches using Spark and Hive.  
By working with e-commerce data, you will:  
- Load and query structured warehouse data.  
- Contrast it with a flexible data lake approach.  
- Understand the trade-offs between these paradigms.  

## Technologies Used
- **Apache Spark** (for distributed data processing)  
- **Apache Hive** (for SQL-like querying of big data)  
- **HDFS / Cloud Storage** (for storing raw data in a data lake)  



